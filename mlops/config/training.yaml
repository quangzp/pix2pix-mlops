training:
  num_epochs: 100
  batch_size: 16
  learning_rate: 0.0002
  device: "mps" # Change to cuda if using NVIDIA GPU
  save_every: 5
  accumulate_grad_batches: 1

  # Optimizer configuration
  optimizer:
    name: "adam"
    lr: 0.0002
    betas: [0.5, 0.999]
    weight_decay: 0.0

  # Scheduler
  scheduler:
    name: "linear"
    warmup_epochs: 5
    min_lr: 0.00001

  # Training settings
  gradient_clip_val: 1.0
  precision: 32
  fast_dev_run: false
  overfit_batches: 0.0

  # Validation
  val_check_interval: 1.0
  check_val_every_n_epoch: 1
  log_every_n_steps: 50

  # Early stopping
  early_stopping:
    monitor: "val/loss"
    patience: 10
    mode: "min"

  # Checkpointing
  checkpoint:
    monitor: "val/loss"
    mode: "min"
    save_top_k: 3
    save_last: true
