{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7cddc15d",
   "metadata": {},
   "source": [
    "## 1. Setup and Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468ed762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import datetime\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110696ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import components from mlops\n",
    "from mlops.src.components.generator import define_G\n",
    "from mlops.src.components.discriminator import define_D\n",
    "from mlops.src.components.losses import GANLoss, VGGLoss\n",
    "from mlops.src.components.replay_pool import ReplayPool\n",
    "from mlops.src.components.functions import print_network, show_tensor\n",
    "from mlops.src.models.pix2pixhd_module import Pix2PixHD, Pix2PixHDDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092d34cb",
   "metadata": {},
   "source": [
    "## 2. Initialize Device and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6faa1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a698071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator configuration\n",
    "generator = define_G(\n",
    "    input_nc=3,\n",
    "    output_nc=3,\n",
    "    ngf=64,\n",
    "    netG=\"global\",\n",
    "    norm=\"instance\",\n",
    "    n_downsample_global=3,\n",
    "    n_blocks_global=9,\n",
    "    n_local_enhancers=1,\n",
    "    n_blocks_local=3,\n",
    "    gpu_ids=[]\n",
    ").to(device)\n",
    "\n",
    "print(\"\\nGenerator Architecture:\")\n",
    "print_network(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3951a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator configuration\n",
    "discriminator = define_D(\n",
    "    input_nc=6,  # 3 (input) + 3 (output)\n",
    "    ndf=64,\n",
    "    n_layers_D=3,\n",
    "    norm=\"instance\",\n",
    "    use_sigmoid=False,\n",
    "    num_D=3,  # Multi-scale discriminator\n",
    "    getIntermFeat=True,\n",
    "    gpu_ids=[],\n",
    "    num_outputs=1\n",
    ").to(device)\n",
    "\n",
    "print(\"\\nDiscriminator Architecture:\")\n",
    "print_network(discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f0e4ad",
   "metadata": {},
   "source": [
    "## 3. Configure Loss Functions and Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e3c89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss functions\n",
    "criterion_gan = GANLoss(use_lsgan=True).to(device)\n",
    "criterion_feat = nn.L1Loss().to(device)\n",
    "criterion_vgg = VGGLoss().to(device)\n",
    "\n",
    "print(\"Loss functions initialized:\")\n",
    "print(f\"  - GAN Loss: {type(criterion_gan).__name__}\")\n",
    "print(f\"  - Feature Loss: {type(criterion_feat).__name__}\")\n",
    "print(f\"  - VGG Loss: {type(criterion_vgg).__name__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ea3084",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create replay buffer for discriminator training\n",
    "replay_pool = ReplayPool(pool_size=50)\n",
    "print(f\"Replay pool initialized with size: 50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d3245b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizers\n",
    "learning_rate = 1e-4\n",
    "g_optimizer = torch.optim.AdamW(generator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "d_optimizer = torch.optim.AdamW(discriminator.parameters(), lr=learning_rate, betas=(0.5, 0.999))\n",
    "\n",
    "print(f\"Optimizers configured with learning rate: {learning_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35a9357",
   "metadata": {},
   "source": [
    "## 4. Prepare Dataset and DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ec9459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset configuration\n",
    "dataset_path = Path(\"./data\")  # Adjust to your dataset location\n",
    "feature_folder = \"/sketches/\"  # Subfolder for input images\n",
    "label_folder = \"/photos/\"      # Subfolder for target images\n",
    "\n",
    "print(f\"Loading dataset from: {dataset_path}\")\n",
    "print(f\"  Feature folder: {feature_folder}\")\n",
    "print(f\"  Label folder: {label_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e3f730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "full_dataset = Pix2PixHDDataset(\n",
    "    images_dir=str(dataset_path),\n",
    "    feature_fold=feature_folder,\n",
    "    label_fold=label_folder,\n",
    "    img_size=256\n",
    ")\n",
    "\n",
    "print(f\"Total dataset size: {len(full_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a718b177",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create train/test split\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "test_size = len(full_dataset) - train_size\n",
    "train_ds, test_ds = random_split(full_dataset, [train_size, test_size])\n",
    "\n",
    "print(f\"\\nData split:\")\n",
    "print(f\"  Train size: {len(train_ds)}\")\n",
    "print(f\"  Test size: {len(test_ds)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a51a00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoaders\n",
    "batch_size = 4\n",
    "num_workers = 4\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,\n",
    "    drop_last=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "print(f\"\\nDataLoaders created:\")\n",
    "print(f\"  Batch size: {batch_size}\")\n",
    "print(f\"  Num workers: {num_workers}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb27f40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize sample batch\n",
    "src_sample, tgt_sample = next(iter(train_loader))\n",
    "print(f\"Sample batch shapes:\")\n",
    "print(f\"  Input (src): {src_sample.shape}\")\n",
    "print(f\"  Target (tgt): {tgt_sample.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dadb324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display sample images\n",
    "print(\"Input image sample:\")\n",
    "show_tensor(src_sample[0])\n",
    "\n",
    "print(\"\\nTarget image sample:\")\n",
    "show_tensor(tgt_sample[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feaf3b24",
   "metadata": {},
   "source": [
    "## 5. Initialize Pix2PixHD Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77e6ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoint directory\n",
    "checkpoint_dir = \"./checkpoints/pix2pixhd/\"\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "os.makedirs(os.path.join(checkpoint_dir, \"images\"), exist_ok=True)\n",
    "\n",
    "print(f\"Checkpoint directory: {checkpoint_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ee8fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Pix2PixHD model\n",
    "model = Pix2PixHD(\n",
    "    generator=generator,\n",
    "    discriminator=discriminator,\n",
    "    criterion_gan=criterion_gan,\n",
    "    criterion_feat=criterion_feat,\n",
    "    criterion_vgg=criterion_vgg,\n",
    "    replay_pool=replay_pool,\n",
    "    device=device,\n",
    "    checkpoint_dir=checkpoint_dir,\n",
    "    lambda_feat=10.0\n",
    ")\n",
    "\n",
    "print(\"Pix2PixHD model initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24265740",
   "metadata": {},
   "source": [
    "## 6. Execute Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87fece0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "num_epochs = 15\n",
    "resume_from_checkpoint = None  # Set to checkpoint path to resume training\n",
    "\n",
    "# Load checkpoint if resuming\n",
    "start_epoch = 0\n",
    "if resume_from_checkpoint is not None:\n",
    "    print(f\"Loading checkpoint from: {resume_from_checkpoint}\")\n",
    "    model.load_checkpoint(resume_from_checkpoint)\n",
    "    # You may need to extract epoch number from checkpoint filename\n",
    "    print(\"Checkpoint loaded successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c98ac95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Starting Pix2PixHD Training\")\n",
    "print(\"=\"*80 + \"\\n\")\n",
    "\n",
    "for epoch in range(start_epoch, num_epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    try:\n",
    "        model.train_epoch(\n",
    "            train_loader=train_loader,\n",
    "            test_loader=test_loader,\n",
    "            epoch=epoch,\n",
    "            g_optimizer=g_optimizer,\n",
    "            d_optimizer=d_optimizer\n",
    "        )\n",
    "        print(f\"✓ Epoch {epoch + 1} completed successfully\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error during epoch {epoch + 1}: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Training completed successfully!\")\n",
    "print(f\"Checkpoints saved to: {checkpoint_dir}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17178ccc",
   "metadata": {},
   "source": [
    "## 7. Inference and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5baae7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions on test set\n",
    "def generate_test_output(model, test_loader, num_samples=4):\n",
    "    \"\"\"Generate and visualize model predictions on test samples\"\"\"\n",
    "    model.generator_ema.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, (src, tgt) in enumerate(test_loader):\n",
    "            if i >= num_samples:\n",
    "                break\n",
    "            \n",
    "            src = src.to(device)\n",
    "            tgt = tgt.to(device)\n",
    "            \n",
    "            # Generate predictions\n",
    "            pred = model.generator_ema(src)\n",
    "            \n",
    "            print(f\"\\nSample {i+1}:\")\n",
    "            print(\"Input:\")\n",
    "            show_tensor(src[0])\n",
    "            \n",
    "            print(\"\\nGenerated:\")\n",
    "            show_tensor(pred[0])\n",
    "            \n",
    "            print(\"\\nTarget:\")\n",
    "            show_tensor(tgt[0])\n",
    "    \n",
    "    model.generator_ema.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ca531c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference\n",
    "print(\"Generating test outputs...\")\n",
    "generate_test_output(model, test_loader, num_samples=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f958b4",
   "metadata": {},
   "source": [
    "## 8. Save Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66a236e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final trained model\n",
    "final_checkpoint_path = os.path.join(checkpoint_dir, \"final_model.pt\")\n",
    "torch.save({\n",
    "    \"G\": model.generator_ema.state_dict(),\n",
    "    \"D\": model.discriminator.state_dict()\n",
    "}, final_checkpoint_path)\n",
    "\n",
    "print(f\"Final model saved to: {final_checkpoint_path}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
