# ğŸ¨ Pix2PixHD MLOps: High-Resolution Image Synthesis Pipeline

![Python](https://img.shields.io/badge/python-3.10-blue.svg)
![PyTorch Lightning](https://img.shields.io/badge/pytorch--lightning-2.0+-orange.svg)
![DVC](https://img.shields.io/badge/data%20version%20control-DVC-9cf.svg)
![Build Status](https://img.shields.io/github/actions/workflow/status/yourusername/pix2pix-mlops/ci.yaml?branch=main)
![License](https://img.shields.io/badge/license-MIT-green)

> **Dá»± Ã¡n xÃ¢y dá»±ng pipeline MLOps toÃ n diá»‡n cho mÃ´ hÃ¬nh Pix2PixHD (High-Definition Image-to-Image Translation), táº­p trung vÃ o kháº£ nÄƒng tÃ¡i láº­p (Reproducibility), tá»± Ä‘á»™ng hÃ³a (Automation) vÃ  quy trÃ¬nh Hybrid Training (Local/Cloud).**

---

## ğŸš€ Giá»›i thiá»‡u (Overview)

Dá»± Ã¡n nÃ y triá»ƒn khai thuáº­t toÃ¡n **Pix2PixHD** (sá»­ dá»¥ng *Global Generator* vÃ  *Multiscale Discriminator*) Ä‘á»ƒ táº¡o ra hÃ¬nh áº£nh Ä‘á»™ phÃ¢n giáº£i cao (vÃ­ dá»¥: chuyá»ƒn báº£n Ä‘á»“ ngá»¯ nghÄ©a thÃ nh áº£nh thÃ nh phá»‘).

Äiá»ƒm Ä‘áº·c biá»‡t cá»§a dá»± Ã¡n khÃ´ng náº±m á»Ÿ thuáº­t toÃ¡n má»›i, mÃ  á»Ÿ viá»‡c **chuáº©n hÃ³a quy trÃ¬nh phÃ¡t triá»ƒn theo tiÃªu chuáº©n MLOps**, giáº£i quyáº¿t cÃ¡c váº¥n Ä‘á» thá»±c táº¿:
* **Quáº£n lÃ½ dá»¯ liá»‡u:** Xá»­ lÃ½ versioning cho dá»¯ liá»‡u áº£nh lá»›n báº±ng DVC.
* **Module hÃ³a:** TÃ¡ch biá»‡t code nghiÃªn cá»©u (Notebooks) vÃ  code sáº£n pháº©m (`src`).
* **Hybrid Training:** PhÃ¡t triá»ƒn trÃªn local, huáº¥n luyá»‡n trÃªn Google Colab, vÃ  quáº£n lÃ½ káº¿t quáº£ táº­p trung.
* **CI/CD:** Tá»± Ä‘á»™ng kiá»ƒm tra lá»—i code vÃ  tÃ­ch há»£p quy trÃ¬nh Ä‘Ã³ng gÃ³i.

---

## ğŸ›  Tech Stack

| ThÃ nh pháº§n | CÃ´ng nghá»‡ sá»­ dá»¥ng | Má»¥c Ä‘Ã­ch |
| :--- | :--- | :--- |
| **Language** | Python 3.10 | NgÃ´n ngá»¯ láº­p trÃ¬nh chÃ­nh |
| **Core Framework** | PyTorch, PyTorch Lightning | XÃ¢y dá»±ng Model, Training Loop vÃ  Logging |
| **Data Management** | DVC (Data Version Control) | Quáº£n lÃ½ version dá»¯ liá»‡u & Model artifacts |
| **Config Management** | Hydra | Quáº£n lÃ½ Hyperparameters linh hoáº¡t (`config.yaml`) |
| **Storage** | Google Drive / S3 | Remote Storage cho DVC |
| **Experiment Tracking** | Weights & Biases (WandB) | Theo dÃµi Loss, Visualize áº£nh sinh ra realtime |
| **CI/CD** | GitHub Actions | Tá»± Ä‘á»™ng test (Unit/Integration) vÃ  Build Docker |
| **Environment** | Docker, Conda | ÄÃ³ng gÃ³i mÃ´i trÆ°á»ng Ä‘á»ƒ tÃ¡i láº­p káº¿t quáº£ |
| **Structure** | Cookiecutter Data Science | Cáº¥u trÃºc thÆ° má»¥c chuáº©n |

---

## ğŸ“‚ Cáº¥u trÃºc dá»± Ã¡n (Project Structure)

Dá»± Ã¡n tuÃ¢n theo chuáº©n `cookiecutter-data-science` Ä‘Ã£ Ä‘Æ°á»£c tÃ¹y biáº¿n cho Deep Learning:

```
â”œâ”€â”€ LICENSE            <- Open-source license if one is chosen
â”œâ”€â”€ Makefile           <- Makefile with convenience commands like `make data` or `make train`
â”œâ”€â”€ README.md          <- The top-level README for developers using this project.
â”œâ”€â”€ data
â”‚   â”œâ”€â”€ external       <- Data from third party sources.
â”‚   â”œâ”€â”€ interim        <- Intermediate data that has been transformed.
â”‚   â”œâ”€â”€ processed      <- The final, canonical data sets for modeling.
â”‚   â””â”€â”€ raw            <- The original, immutable data dump.
â”‚
â”œâ”€â”€ docs               <- A default mkdocs project; see www.mkdocs.org for details
â”‚
â”œâ”€â”€ notebooks          <- Jupyter notebooks. Naming convention is a number (for ordering),
â”‚                         the creator's initials, and a short `-` delimited description, e.g.
â”‚                         `1.0-jqp-initial-data-exploration`.
â”‚
â”œâ”€â”€ pyproject.toml     <- Project configuration file with package metadata for
â”‚                         mlops and configuration for tools like black
â”‚
â”œâ”€â”€ references         <- Data dictionaries, manuals, and all other explanatory materials.
â”‚
â”œâ”€â”€ reports            <- Generated analysis as HTML, PDF, LaTeX, etc.
â”‚   â””â”€â”€ figures        <- Generated graphics and figures to be used in reporting
â”‚
â”œâ”€â”€ requirements.txt   <- The requirements file for reproducing the analysis environment, e.g.
â”‚                         generated with `pip freeze > requirements.txt`
â”‚
â”œâ”€â”€ setup.cfg          <- Configuration file for flake8
â”‚
â””â”€â”€ mlops   <- Source code for use in this project.
    â”‚
    â”œâ”€â”€ __init__.py             <- Makes mlops a Python module
    â”‚
    â”œâ”€â”€ config.py               <- Store useful variables and configuration
    â”‚
    â”œâ”€â”€ dataset.py              <- Scripts to download or generate data
    â”‚
    â”œâ”€â”€ features.py             <- Code to create features for modeling
    â”‚
    â”œâ”€â”€ modeling
    â”‚   â”œâ”€â”€ __init__.py
    â”‚   â”œâ”€â”€ predict.py          <- Code to run model inference with trained models
    â”‚   â””â”€â”€ train.py            <- Code to train models
    â”‚
    â””â”€â”€ plots.py                <- Code to create visualizations
```

--------

## Getting Started

### 1. CÃ i Ä‘áº·t mÃ´i trÆ°á»ng
Khuyáº¿n khÃ­ch sá»­ dá»¥ng Conda Ä‘á»ƒ quáº£n lÃ½ Python vÃ  CUDA:

```bash
# Clone dá»± Ã¡n
git clone [https://github.com/quangzp/pix2pix-mlops.git](https://github.com/quangzp/pix2pix-mlops.git)
cd pix2pix-mlops

# Táº¡o mÃ´i trÆ°á»ng áº£o
conda create -n pix2pix python=3.10
conda activate pix2pix

# CÃ i Ä‘áº·t thÆ° viá»‡n
pip install -r requirements.txt
```

### 2. Chuáº©n bá»‹ dá»¯ liá»‡u (DVC)

```bash
# Cáº¥u hÃ¬nh xÃ¡c thá»±c, storage (náº¿u cáº§n) vÃ  táº£i dá»¯ liá»‡u + model cÅ© (náº¿u cÃ³)
dvc pull
```

### 3. Huáº¥n luyá»‡n (Training)
Cháº¡y training vá»›i cáº¥u hÃ¬nh máº·c Ä‘á»‹nh hoáº·c tÃ¹y chá»‰nh qua Hydra mÃ  khÃ´ng cáº§n sá»­a code:
```bash
# Cháº¡y máº·c Ä‘á»‹nh (theo conf/config.yaml)
python src/train.py

# Cháº¡y tÃ¹y chá»‰nh (VÃ­ dá»¥: Train 200 epochs, batch size 4)
python src/train.py train.max_epochs=200 data.batch_size=4

# Cháº¡y vá»›i WandB logging (cáº§n login wandb trÆ°á»›c)
python src/train.py logger=wandb
```

### 4. Suy luáº­n (Inference)
Sinh áº£nh tá»« model Ä‘Ã£ train:
```bash
python src/predict.py \
    --ckpt_path models/best_model.ckpt \
    --input_path data/test/sample_input.jpg \
    --output_path results/generated.jpg
```

# ğŸ”„ Quy trÃ¬nh MLOps (Hybrid Workflow)

TÃ i liá»‡u nÃ y mÃ´ táº£ quy trÃ¬nh lÃ m viá»‡c chuáº©n cho dá»± Ã¡n Pix2PixHD, káº¿t há»£p giá»¯a mÃ´i trÆ°á»ng phÃ¡t triá»ƒn cá»¥c bá»™ (Local) vÃ  huáº¥n luyá»‡n trÃªn Cloud (Google Colab) Ä‘á»ƒ tá»‘i Æ°u chi phÃ­ vÃ  hiá»‡u quáº£.

## ğŸ—ºï¸ SÆ¡ Ä‘á»“ tá»•ng quan

```mermaid
graph TD
    subgraph Local_Dev [MÃ¡y CÃ¡ NhÃ¢n]
        A[Viáº¿t Code / Config] -->|Git Push| B(GitHub Repo)
        C[Dá»¯ liá»‡u Má»›i] -->|DVC Push| D(Storage)
    end

    subgraph CI_CD [GitHub Actions]
        B -->|Pull Request| E{Cháº¡y Test}
        E -->|Pass| F[Merge vÃ o Main]
        E -->|Fail| A
    end

    subgraph Cloud_Training [VPS GPU]
        F -->|Git Trigger Self-host runner| G[VPS]
        D -->|DVC Pull| G
        G -->|Train| H[Model Artifacts]
        H -->|WandB Log| I(WandB Dashboard)
        H -->|DVC Push| D
    end

    subgraph Versioning
        G -->|Git Push .dvc| B
    end
```

### ğŸ“Š Káº¿t quáº£ (Results)

